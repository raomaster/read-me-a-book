# üìö read-me-a-book

**read-me-a-book** es una herramienta para convertir PDFs (incluyendo escaneados) y texto en archivos de audio. Utiliza OCR para PDFs basados en im√°genes y motores TTS locales o servicios gratuitos.


*Nota: Para el desarrollo de este proyecto, se utilizaron herramientas de IA como Gemini y ChatGPT como apoyo en la investigaci√≥n y la realizaci√≥n de pruebas de concepto.*

---

## üöÄ Caracter√≠sticas Principales

-   üìÑ Extracci√≥n de texto desde PDFs (digitales y escaneados mediante OCR).
-   üó£Ô∏è Conversi√≥n de texto a voz utilizando:
    -   **gTTS**: Gratuito, online, f√°cil de usar.
    -   **Piper TTS**: Local, alta calidad, requiere configuraci√≥n adicional.
-   ‚öôÔ∏è Funciona 100% localmente (con Piper TTS) o con conexi√≥n a internet (con gTTS).
-   üé∂ Une fragmentos de audio generados en un solo archivo (`_full.mp3` o `_full.wav`).
-   üåê API RESTful con Flask y Swagger para una f√°cil integraci√≥n.
-   üìÑ Soporte para procesar rangos de p√°ginas espec√≠ficos en PDFs.
-   üñºÔ∏è Preprocesamiento de im√°genes (escala de grises, binarizaci√≥n con Otsu) para mejorar la precisi√≥n del OCR.


---

## ‚öôÔ∏è Tecnolog√≠as utilizadas

-   **Python**: Lenguaje principal.
-   **Flask**: Para la API web.
-   **Flasgger**: Para la documentaci√≥n Swagger UI.
-   **Pytesseract**: Para Tesseract OCR.
-   **pdf2image**: Para convertir PDFs a im√°genes.
-   **gTTS**: Google Text-to-Speech.
-   **Piper TTS**: Motor TTS local (ejecutado a trav√©s de `subprocess`).
-   **Pydub**: Para manipulaci√≥n y uni√≥n de audio.
-   **Pillow (PIL)**: Para manipulaci√≥n de im√°genes.
-   **OpenCV (cv2)**: Para preprocesamiento de im√°genes.
-   **Numpy**: Para manipulaci√≥n de arrays de im√°genes.

---

## üß∞ Requisitos
- Python 3.10 o superior.
- Git
- **FFmpeg**: Necesario para `pydub` (manipulaci√≥n de audio).
    -   Desc√°rgalo desde ffmpeg.org.
    -   Aseg√∫rate de a√±adir el directorio `bin` de FFmpeg a la variable de entorno PATH de tu sistema.

---
## üõ†Ô∏è Herramientas Externas Requeridas

### 1. Tesseract OCR
-   **Por qu√©**: Para extraer texto de PDFs escaneados (OCR).
-   **Instalaci√≥n**:
    -   Linux: `sudo apt-get install tesseract-ocr tesseract-ocr-spa`
    -   Windows: Descarga el instalador desde el repositorio oficial de Tesseract en GitHub (UB Mannheim). Durante la instalaci√≥n, aseg√∫rate de seleccionar los paquetes de idioma que necesites (ej. "Spanish"). A√±ade la ruta de instalaci√≥n de Tesseract al PATH del sistema, o config√∫rala en `src/server.py` (variable `TESSERACT_INSTALL_PATH`).
    -   macOS: `brew install tesseract tesseract-lang`
    -   **Importante**: Para espa√±ol, se recomienda descargar el archivo `spa.traineddata` (idealmente de `tessdata_best` para mayor precisi√≥n) y colocarlo en el directorio `tessdata` de tu instalaci√≥n de Tesseract (link: https://github.com/tesseract-ocr/tessdata_best/blob/main/spa.traineddata ).
        -   Tessdata_best repository

### 2. Poppler
-   **Por qu√©**: `pdf2image` lo necesita para convertir PDFs a im√°genes.
-   **Instalaci√≥n**:
    -   Linux: `sudo apt-get install poppler-utils`
    -   **Windows**:
        1.  Descarga los binarios de Poppler. Algunas fuentes comunes son:
            *   Poppler for Windows (oschwartz10612) (busca la √∫ltima versi√≥n, ej. `poppler-24.02.0-0.zip`).
            *   Poppler Binaries by UB Mannheim (a menudo referenciado en la documentaci√≥n de `pdf2image`).
        2.  Extrae el contenido del archivo ZIP a una ubicaci√≥n en tu sistema (ej. `C:\poppler-24.02.0`).
        3.  A√±ade la ruta a la subcarpeta `bin` (que usualmente est√° dentro de una carpeta como `Library` o directamente, ej. `C:\poppler-24.02.0\Library\bin` o `C:\poppler-24.02.0\bin`) al PATH de tu sistema.
        4.  **Alternativa (Recomendada para Windows)**: En lugar de modificar el PATH del sistema, puedes configurar la ruta a la carpeta `bin` de Poppler directamente en el archivo `src/server.py`. Busca la variable `POPPLER_PATH`, descom√©ntala si es necesario, y aj√∫stala seg√∫n tu instalaci√≥n:
            ```python
            # En src/server.py, ajusta esta l√≠nea:
            # POPPLER_PATH = r"C:\Program Files\poppler-24.08.0\Library\bin" # ¬°AJUSTA ESTA RUTA!
            ```
            El c√≥digo en `src/server.py` ya est√° preparado para usar esta variable si est√° definida, pas√°ndola al argumento `poppler_path` de `convert_from_path`.
    -   macOS: `brew install poppler`


### 3. Piper TTS (Opcional, para TTS local de alta calidad)

-   **Por qu√©**: Alternativa local a gTTS, ofrece voces de alta calidad y mayor control, funcionando offline.
-   **Instalaci√≥n y Configuraci√≥n**:
    1.  **Descarga el ejecutable de Piper TTS**: Ve al repositorio de Piper en GitHub y descarga la versi√≥n adecuada para tu sistema operativo.
    2.  **Coloca el ejecutable**: Guarda `piper.exe` (o el ejecutable correspondiente) en una ubicaci√≥n accesible.
    3.  **Configura la ruta en `src/server.py`**: Ajusta la variable `PIPER_EXECUTABLE_PATH` en `src/server.py` para que apunte a tu ejecutable de Piper:
        ```python
        # En src/server.py, ajusta esta l√≠nea:
        PIPER_EXECUTABLE_PATH = r"C:\Ruta\A\Tu\piper\piper.exe" # ¬°AJUSTA ESTA RUTA!
        ```
    4.  **Descarga modelos de voz**:
        *   Los modelos de voz para Piper (archivos `.onnx` y su correspondiente `.onnx.json`) se pueden encontrar en Hugging Face (rhasspy/piper-voices).
        *   Descarga los modelos que desees. Cada modelo generalmente viene con un archivo `.onnx` y un archivo `.onnx.json`.
    5.  **Organiza los modelos**:
        *   Crea una carpeta `models` en la ra√≠z de tu proyecto (al mismo nivel que la carpeta `src`).
        *   Dentro de `models`, organiza los archivos de voz seg√∫n la estructura esperada por la configuraci√≥n `PIPER_VOICES` en `src/server.py`. Por ejemplo, para las voces configuradas:
            *   Para `"es_MX-claude-high"`:
                *   Crea la carpeta `models/es_MX/`.
                *   Coloca `es_MX-claude-high.onnx` (y su `.json` si existe) dentro de `models/es_MX/`.
            *   Para `"es_ES-mls_9972-low"`:
                *   Crea la carpeta `models/es_ES-mls_9972-low/`.
                *   Coloca `es_ES-mls_9972-low.onnx` (y su `.json` si existe) dentro de `models/es_ES-mls_9972-low/`.
            *   La estructura general ser√≠a:
                ```
                read-me-a-book/
                ‚îú‚îÄ‚îÄ models/
                ‚îÇ   ‚îú‚îÄ‚îÄ es_MX/
                ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ es_MX-claude-high.onnx
                ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ es_MX-claude-high.onnx.json (si aplica)
                ‚îÇ   ‚îî‚îÄ‚îÄ es_ES-mls_9972-low/
                ‚îÇ       ‚îú‚îÄ‚îÄ es_ES-mls_9972-low.onnx
                ‚îÇ       ‚îî‚îÄ‚îÄ es_ES-mls_9972-low.onnx.json (si aplica)
                ‚îú‚îÄ‚îÄ src/
                ‚îÇ   ‚îî‚îÄ‚îÄ server.py
                ‚îî‚îÄ‚îÄ README.md
                ```
    6.  **Verifica/Configura las voces en `src/server.py`**: El diccionario `PIPER_VOICES` en `src/server.py` ya define las rutas. Aseg√∫rate de que los nombres de archivo y las rutas coincidan con los modelos que has descargado y su ubicaci√≥n.
        ```python
        # En src/server.py (esto ya est√° configurado, solo verifica que tus archivos coincidan):
        PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        PIPER_MODELS_BASE_DIR = os.path.join(PROJECT_ROOT, "models")

        PIPER_VOICES = {
            "es_MX-claude-high": {
                "model_path": os.path.join(PIPER_MODELS_BASE_DIR, "es_MX", "es_MX-claude-high.onnx"),
                "description": "Voz Claude en Espa√±ol (M√©xico) - Alta calidad"
            },
            "es_ES-mls_9972-low": {
                "model_path": os.path.join(PIPER_MODELS_BASE_DIR, "es_ES-mls_9972-low", "es_ES-mls_9972-low.onnx"),
                "description": "Voz MLS en Espa√±ol (Espa√±a) - Baja calidad"
            }
            # A√±ade m√°s voces aqu√≠ si es necesario, siguiendo el patr√≥n de rutas.
        }
        ```

---

## üì¶ Instalaci√≥n del Proyecto

1.  **Clona el repositorio:**
    ```bash
    git clone https://github.com/tu-usuario/read-me-a-book.git # Reemplaza con la URL de tu repositorio
    cd read-me-a-book
    ```

2.  **Crea un entorno virtual (recomendado):**
    ```bash
    python -m venv venv
    # En Windows
    venv\Scripts\activate
    # En macOS/Linux
    source venv/bin/activate
    ```

3.  **Instala las dependencias de Python:**
    ```bash
    pip install Flask flasgger gTTS pdf2image Pillow opencv-python pydub numpy pytesseract
    ```

---

## üöÄ Uso

1.  **Configura las rutas (si es necesario)**: Verifica que las rutas a Tesseract, Poppler (especialmente en Windows si no est√° en PATH), y Piper (ejecutable y modelos) est√©n correctamente configuradas en `src/server.py` como se describe en la secci√≥n "Herramientas Externas Requeridas".

2.  **Inicia el servidor Flask:**
    Desde el directorio ra√≠z del proyecto (donde est√° la carpeta `src`):
    ```bash
    # Aseg√∫rate de que tu entorno virtual est√© activado

    # Opci√≥n 1: Ejecutando el script directamente (recomendado si __main__ est√° configurado)
    python src/server.py

    # Opci√≥n 2: Usando el comando flask
    # En macOS/Linux:
    # export FLASK_APP=src.server
    # En Windows (cmd):
    # set FLASK_APP=src.server
    # En Windows (PowerShell):
    # $env:FLASK_APP="src.server"
    #
    # flask run --host=0.0.0.0 --port=5000
    ```
    El servidor estar√° disponible en `http://localhost:5000` (o la IP y puerto que configure `app.run`).

3.  **Accede a la API:**
    -   **Swagger UI (documentaci√≥n interactiva de la API)**: Abre tu navegador y ve a `http://localhost:5000/apidocs`
    -   **Endpoints principales**:
        -   `POST /process-pdf`: Sube un archivo PDF, extrae texto y lo convierte a audio.
        -   `POST /text-to-audio`: Convierte un texto JSON proporcionado a audio.
        -   `GET /outputs/<filename>`: Sirve los archivos de texto y audio generados.

### Ejemplo de uso con `curl` para `/process-pdf`:

```bash
curl -X POST -F "file=@/ruta/completa/a/tu/libro.pdf" \
             -F "lang=es" \
             -F "tts_engine=piper" \
             -F "piper_voice=es_MX-claude-high" \
             -F "start_page=5" \
             -F "end_page=10" \
             http://localhost:5000/process-pdf

```
Reemplaza /ruta/completa/a/tu/libro.pdf con la ruta real a tu archivo. Si usas gtts, cambia el motor y omite piper_voice: -F "tts_engine=gtts".

### Ejemplo de uso con curl para /text-to-audio:

```bash
curl -X POST -H "Content-Type: application/json" \
             -d '{
                   "text": "Hola mundo, esto es una prueba de conversi√≥n de texto a voz.",
                   "lang": "es",
                   "tts_engine": "gtts"
                 }' \
             http://localhost:5000/text-to-audio
```


Para usar Piper TTS:

```bash
curl -X POST -H "Content-Type: application/json" \
             -d '{
                   "text": "Hola mundo con Piper TTS.",
                   "lang": "es",
                   "tts_engine": "piper",
                   "piper_voice": "es_MX-claude-high"
                 }' \
             http://localhost:5000/text-to-audio

```

---
## üìÅ Estructura de Carpetas Esperada

El servidor crea y utiliza las siguientes carpetas dentro del directorio ra√≠z del proyecto:

uploads/: Para los archivos PDF subidos temporalmente.
outputs/: Para los archivos de texto (.txt) y audio (_full.mp3 o _full.wav) generados.
models/ (debes crearla t√∫ y poblarla): Para almacenar los modelos de Piper TTS, como se describe en la secci√≥n de instalaci√≥n de Piper.

---
## üìù Notas Adicionales

L√≠mites de gTTS: gTTS es un servicio online y puede tener l√≠mites en la longitud del texto o frecuencia de solicitudes. El script divide el texto en fragmentos m√°s peque√±os (basado en _split_text_into_chunks con max_length=48000) y a√±ade un retraso (time.sleep(5)) entre fragmentos para mitigar problemas. Para textos muy largos o uso intensivo, Piper TTS (local) es m√°s robusto.
Calidad de OCR: La calidad de la extracci√≥n de texto OCR depende en gran medida de la calidad del PDF escaneado. El preprocesamiento de im√°genes implementado (escala de grises, binarizaci√≥n con Otsu) ayuda, pero los resultados pueden variar.
Configuraci√≥n de Idioma: Aseg√∫rate de que los paquetes de idioma correctos para Tesseract est√©n instalados (ej. spa para espa√±ol, eng para ingl√©s) y que el c√≥digo de idioma (lang) proporcionado a la API sea compatible con los motores TTS y Tesseract. El script mapea es a spa y en a eng para Tesseract internamente.
Archivos de Salida: Los archivos de audio generados se guardan en la carpeta outputs/ con un nombre base √∫nico seguido de _full.mp3 (para gTTS) o _full.wav (para Piper TTS). Los archivos de texto tambi√©n se guardan en outputs/ con un nombre √∫nico y extensi√≥n .txt.

---
## ü§ù Contribuciones
Las contribuciones son bienvenidas. Por favor, abre un issue para discutir cambios o un pull request con tus mejoras.